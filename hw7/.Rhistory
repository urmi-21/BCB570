xtest <- x[-tindex,]
ytrain <- y[tindex]
ytest <- y[-tindex]
istrain=rep(0,n)
istrain[tindex]=1
#####start training#######
svp <- ksvm(xtrain,ytrain,type="C-svc",kernel='vanilladot',C=c)
ypred = predict(svp,xtest)
predList<-cbind(predList,ypred)
labList<-cbind(labList,ytest)
# Confusion table
cm<-table(ytest,ypred)
acc<-sum(diag(cm))/length(ytest)
#cat("Accuraccy:",acc*100,"%")
thisErr<-1-acc
#print(thisErr)
cvErrs<-c(cvErrs,thisErr)
}
errlin<-c(errlin, mean(cvErrs))
if(bestAcc<mean(cvErrs)){
bestAcc<-mean(cvErrs)
bestMod<-svp
}
}
#################Solution 2###################
##Read data
X1625Data_encoded <- read_csv("1625Data_encoded.txt")
#firsc col is class
y <- X1625Data_encoded$`data11$V2`
x <- X1625Data_encoded[c(2:length(X1625Data_encoded))]
x <- as.matrix(sapply(x, as.numeric))
n<-length(y)
N<-5
#initialize c list
clist <- 2^seq(-1,10)
errlin <- numeric(length(clist))
predList<-c()
labList<-c()
##implement cross validation
for(c in clist){
cvErrs<-c()
for(i in(1:N)){
#split data into train and cross
tindex <- sample(n,round(n*.9)) # indices of training samples to plot
xtrain <- x[tindex,]
xtest <- x[-tindex,]
ytrain <- y[tindex]
ytest <- y[-tindex]
istrain=rep(0,n)
istrain[tindex]=1
#####start training#######
svp <- ksvm(xtrain,ytrain,type="C-svc",kernel='vanilladot',C=c)
ypred = predict(svp,xtest)
predList<-cbind(predList,ypred)
labList<-cbind(labList,ytest)
# Confusion table
cm<-table(ytest,ypred)
acc<-sum(diag(cm))/length(ytest)
#cat("Accuraccy:",acc*100,"%")
thisErr<-1-acc
#print(thisErr)
cvErrs<-c(cvErrs,thisErr)
}
errlin<-c(errlin, mean(cvErrs))
if(bestAcc<mean(cvErrs)){
bestAcc<-mean(cvErrs)
bestMod<-svp
}
}
rm(list=ls())
#################Solution 2###################
##Read data
X1625Data_encoded <- read_csv("1625Data_encoded.txt")
#firsc col is class
y <- X1625Data_encoded$`data11$V2`
x <- X1625Data_encoded[c(2:length(X1625Data_encoded))]
x <- as.matrix(sapply(x, as.numeric))
n<-length(y)
N<-5
#initialize c list
clist <- 2^seq(-1,10)
errlin <- numeric(length(clist))
predList<-c()
labList<-c()
bestMod<-c()
bestAcc<--1
##implement cross validation
for(c in clist){
cvErrs<-c()
for(i in(1:N)){
#split data into train and cross
tindex <- sample(n,round(n*.9)) # indices of training samples to plot
xtrain <- x[tindex,]
xtest <- x[-tindex,]
ytrain <- y[tindex]
ytest <- y[-tindex]
istrain=rep(0,n)
istrain[tindex]=1
#####start training#######
svp <- ksvm(xtrain,ytrain,type="C-svc",kernel='vanilladot',C=c)
ypred = predict(svp,xtest)
predList<-cbind(predList,ypred)
labList<-cbind(labList,ytest)
# Confusion table
cm<-table(ytest,ypred)
acc<-sum(diag(cm))/length(ytest)
#cat("Accuraccy:",acc*100,"%")
thisErr<-1-acc
#print(thisErr)
cvErrs<-c(cvErrs,thisErr)
}
errlin<-c(errlin, mean(cvErrs))
if(bestAcc<mean(cvErrs)){
bestAcc<-mean(cvErrs)
bestMod<-svp
}
}
#################Solution 2###################
##Read data
X1625Data_encoded <- read_csv("1625Data_encoded.txt")
#firsc col is class
y <- X1625Data_encoded$`data11$V2`
x <- X1625Data_encoded[c(2:length(X1625Data_encoded))]
x <- as.matrix(sapply(x, as.numeric))
n<-length(y)
N<-5
#initialize c list
clist <- 2^seq(-1,10)
errlin <- numeric(length(clist))
predList<-c()
labList<-c()
bestMod<-c()
bestAcc<--1
##implement cross validation
for(c in clist){
cvErrs<-c()
for(i in(1:N)){
#split data into train and cross
tindex <- sample(n,round(n*.9)) # indices of training samples to plot
xtrain <- x[tindex,]
xtest <- x[-tindex,]
ytrain <- y[tindex]
ytest <- y[-tindex]
istrain=rep(0,n)
istrain[tindex]=1
#####start training#######
svp <- ksvm(xtrain,ytrain,type="C-svc",kernel='vanilladot',C=c)
ypred = predict(svp,xtest)
predList<-cbind(predList,ypred)
labList<-cbind(labList,ytest)
# Confusion table
cm<-table(ytest,ypred)
acc<-sum(diag(cm))/length(ytest)
#cat("Accuraccy:",acc*100,"%")
thisErr<-1-acc
#print(thisErr)
cvErrs<-c(cvErrs,thisErr)
}
errlin<-c(errlin, mean(cvErrs))
if(bestAcc<mean(cvErrs)){
bestAcc<-mean(cvErrs)
bestMod<-svp
}
}
pred.mat <- prediction(predList, labels = labList )
#plot CV ROCs
many.roc.perf = performance(pred.mat, measure = "tpr", x.measure = "fpr")
plot(many.roc.perf,main="ROC plot for cv sets",col=1,lwd=1)
abline(a=0, b= 1)
plot(clist,errlin,type='l',ylim=c(0,0.1),xlab="C",ylab="Error rate",col=1,lwd=2,main='CrossValidaton error')
plot(clist,errlin,type='l',ylim=c(0,0.1),xlab="C",ylab="Error rate",col=1,lwd=2,main='CrossValidaton error')
clist
errlin
#initialize c list
clist <- 2^seq(-1,10)
errlin <- c()
predList<-c()
labList<-c()
bestMod<-c()
bestAcc<--1
##implement cross validation
for(c in clist){
cvErrs<-c()
for(i in(1:N)){
#split data into train and cross
tindex <- sample(n,round(n*.9)) # indices of training samples to plot
xtrain <- x[tindex,]
xtest <- x[-tindex,]
ytrain <- y[tindex]
ytest <- y[-tindex]
istrain=rep(0,n)
istrain[tindex]=1
#####start training#######
svp <- ksvm(xtrain,ytrain,type="C-svc",kernel='vanilladot',C=c)
ypred = predict(svp,xtest)
predList<-cbind(predList,ypred)
labList<-cbind(labList,ytest)
# Confusion table
cm<-table(ytest,ypred)
acc<-sum(diag(cm))/length(ytest)
#cat("Accuraccy:",acc*100,"%")
thisErr<-1-acc
#print(thisErr)
cvErrs<-c(cvErrs,thisErr)
}
errlin<-c(errlin, mean(cvErrs))
if(bestAcc<mean(cvErrs)){
bestAcc<-mean(cvErrs)
bestMod<-svp
}
}
pred.mat <- prediction(predList, labels = labList )
#plot CV ROCs
many.roc.perf = performance(pred.mat, measure = "tpr", x.measure = "fpr")
plot(many.roc.perf,main="ROC plot for cv sets",col=1,lwd=1)
plot(many.roc.perf,main="ROC plot for cv sets",col=1,lwd=1)
abline(a=0, b= 1)
plot(clist,errlin,type='l',ylim=c(0,0.1),xlab="C",ylab="Error rate",col=1,lwd=2,main='CrossValidaton error')
clist
errlin
##############solution 3
#read data
schillingData_encoded <- read_csv("schillingData_encoded.txt")
#balance class by under sampling
num_pos<-length(which(schillingData_encoded$`data11$V2`==1))
num_neg<-length(which(schillingData_encoded$`data11$V2`==-1))
#balance class by oversampling
schillingData_neg<-schillingData_encoded[which(schillingData_encoded$`data11$V2`==-1),]
schillingData_pos<-schillingData_encoded[which(schillingData_encoded$`data11$V2`==1),]
N<-5
#initialize c list
clist <- 2^seq(-1,10)
errrbf<-c()
bestMod<-c()
bestAcc<--1
predList<-c()
labList<-c()
for(c in clist){
cvErrs<-c()
for(i in(1:N)){
#create a balanced cross val dataset
cv<-data.frame(matrix(ncol = 161, nrow = 0))
colnames(cv)<-colnames(schillingData_encoded)
#sample 10% of data from pos class and equal amount from neg class to make cv set
n_cv<-as.integer(num_pos*0.1)
## set the seed to make your partition reproductible
set.seed(41*i+i**2)
cv_ind <- sample(seq_len(nrow(schillingData_pos)), size = n_cv)
cv_pos <- schillingData_pos[cv_ind, ]
train_pos <- schillingData_pos[-cv_ind, ]
cv_ind <- sample(seq_len(nrow(schillingData_neg)), size = n_cv)
cv_neg <- schillingData_neg[cv_ind, ]
train_neg <- schillingData_neg[-cv_ind, ]
#final CV
cv<-rbind(cv_pos,cv_neg)
#over sample the remaining pos class by replicating randomly
osize=length(train_neg$`data11$V2`)-length(train_pos$`data11$V2`)
oversamp_ind<-sample(seq_len(nrow(schillingData_pos)), size = osize,replace = T)
tr_pos_os<-train_pos[oversamp_ind,]
train_pos<-rbind(train_pos,tr_pos_os)
train_set<-rbind(train_pos,train_neg)
#####start training#######
y <- train_set$`data11$V2`
x <- train_set[c(2:length(train_set))]
x <- as.matrix(sapply(x, as.numeric))
n<-length(y)
#train SVM model
svp <- ksvm(x,y,type="C-svc",kernel="rbf",C=c,scaled=c())
# General summary
svp
xtest<-cv[c(2:length(train_set))]
ytest<-cv$`data11$V2`
ypred = predict(svp,xtest)
predList<-cbind(predList,ypred)
labList<-cbind(labList,ytest)
# Confusion table
cm<-table(ytest,ypred)
acc<-sum(diag(cm))/length(ytest)
#cat("Accuraccy:",acc*100,"%")
thisErr<-1-acc
#print(thisErr)
cvErrs<-c(cvErrs,thisErr)
}
errrbf<-c(errrbf, mean(cvErrs))
if(bestAcc<mean(cvErrs)){
bestAcc<-mean(cvErrs)
bestMod<-svp
}
}
##############solution 3
#read data
schillingData_encoded <- read_csv("schillingData_encoded.txt")
#balance class by under sampling
num_pos<-length(which(schillingData_encoded$`data11$V2`==1))
num_neg<-length(which(schillingData_encoded$`data11$V2`==-1))
#balance class by oversampling
schillingData_neg<-schillingData_encoded[which(schillingData_encoded$`data11$V2`==-1),]
schillingData_pos<-schillingData_encoded[which(schillingData_encoded$`data11$V2`==1),]
N<-5
#initialize c list
clist <- 2^seq(-1,10)
errrbf<-c()
bestMod<-NULL
bestAcc<--1
predList<-c()
labList<-c()
for(c in clist){
cvErrs<-c()
for(i in(1:N)){
#create a balanced cross val dataset
cv<-data.frame(matrix(ncol = 161, nrow = 0))
colnames(cv)<-colnames(schillingData_encoded)
#sample 10% of data from pos class and equal amount from neg class to make cv set
n_cv<-as.integer(num_pos*0.1)
## set the seed to make your partition reproductible
set.seed(41*i+i**2)
cv_ind <- sample(seq_len(nrow(schillingData_pos)), size = n_cv)
cv_pos <- schillingData_pos[cv_ind, ]
train_pos <- schillingData_pos[-cv_ind, ]
cv_ind <- sample(seq_len(nrow(schillingData_neg)), size = n_cv)
cv_neg <- schillingData_neg[cv_ind, ]
train_neg <- schillingData_neg[-cv_ind, ]
#final CV
cv<-rbind(cv_pos,cv_neg)
#over sample the remaining pos class by replicating randomly
osize=length(train_neg$`data11$V2`)-length(train_pos$`data11$V2`)
oversamp_ind<-sample(seq_len(nrow(schillingData_pos)), size = osize,replace = T)
tr_pos_os<-train_pos[oversamp_ind,]
train_pos<-rbind(train_pos,tr_pos_os)
train_set<-rbind(train_pos,train_neg)
#####start training#######
y <- train_set$`data11$V2`
x <- train_set[c(2:length(train_set))]
x <- as.matrix(sapply(x, as.numeric))
n<-length(y)
#train SVM model
svp <- ksvm(x,y,type="C-svc",kernel="rbf",C=c,scaled=c())
# General summary
svp
xtest<-cv[c(2:length(train_set))]
ytest<-cv$`data11$V2`
ypred = predict(svp,xtest)
predList<-cbind(predList,ypred)
labList<-cbind(labList,ytest)
# Confusion table
cm<-table(ytest,ypred)
acc<-sum(diag(cm))/length(ytest)
#cat("Accuraccy:",acc*100,"%")
thisErr<-1-acc
#print(thisErr)
cvErrs<-c(cvErrs,thisErr)
}
errrbf<-c(errrbf, mean(cvErrs))
if(bestAcc<mean(cvErrs)){
bestAcc<-mean(cvErrs)
bestMod<-svp
}
}
pred.mat <- prediction(predList, labels = labList )
#plot CV ROCs
many.roc.perf = performance(pred.mat, measure = "tpr", x.measure = "fpr")
plot(many.roc.perf,main="ROC plot for cv sets",col=1,lwd=1)
abline(a=0, b= 1)
plot(clist,errrbf,type='l',ylim=c(0,0.2),xlab="C",ylab="Error rate",col=1,lwd=2,main='CrossValidaton error')
grid()
legend("topright",c('RBF'),lwd=2,col=c(1))
bestC<--2
bestC<-clist[which.min(errrbf)]
cat("Best C:",bestC,"from RBF using balanced schillingData, Err:", min(errrbf))
bestMod
##predict on test data
#read test set
X1625Data_encoded <- read_csv("1625Data_encoded.txt")
testy<-X1625Data_encoded$`data11$V2`
testx<-X1625Data_encoded[c(2:length(X1625Data_encoded))]
test_pred<- predict(bestMod,testx)
cm<-table(testy,test_pred)
acc<-sum(diag(cm))/length(testy)
cat("Accuraccy on 1625 data using schillingData model:",acc*100,"%")
pred <- prediction(test_pred,testy)
# Plot ROC curve
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf,title="TPR vs. FPR")
abline(a=0, b= 1)
auc<- performance(pred, measure = "auc")
cat("AUC ROC:",unlist(auc@y.values)[1])
# Plot precision/recall curve
perf <- performance(pred, measure = "prec", x.measure = "rec")
plot(perf,title="Precision-Recall")
bestMod
cat("Best C:",bestC,"from RBF using balanced schillingData, Err:", min(errrbf))
errrbf
clist
svp <- ksvm(x,y,type="C-svc",kernel="rbf",C=10,scaled=c())
svp
svp <- ksvm(x,y,type="C-svc",kernel="rbf",C=100,scaled=c())
svp
##############solution 3
#read data
schillingData_encoded <- read_csv("schillingData_encoded.txt")
#balance class by under sampling
num_pos<-length(which(schillingData_encoded$`data11$V2`==1))
num_neg<-length(which(schillingData_encoded$`data11$V2`==-1))
#balance class by oversampling
schillingData_neg<-schillingData_encoded[which(schillingData_encoded$`data11$V2`==-1),]
schillingData_pos<-schillingData_encoded[which(schillingData_encoded$`data11$V2`==1),]
N<-5
#initialize c list
clist <- 2^seq(-1,10)
errrbf<-c()
bestMod<-NULL
bestAcc<--1
predList<-c()
labList<-c()
for(c in clist){
cvErrs<-c()
for(i in(1:N)){
#create a balanced cross val dataset
cv<-data.frame(matrix(ncol = 161, nrow = 0))
colnames(cv)<-colnames(schillingData_encoded)
#sample 10% of data from pos class and equal amount from neg class to make cv set
n_cv<-as.integer(num_pos*0.1)
## set the seed to make your partition reproductible
set.seed(41*i+i**2)
cv_ind <- sample(seq_len(nrow(schillingData_pos)), size = n_cv)
cv_pos <- schillingData_pos[cv_ind, ]
train_pos <- schillingData_pos[-cv_ind, ]
cv_ind <- sample(seq_len(nrow(schillingData_neg)), size = n_cv)
cv_neg <- schillingData_neg[cv_ind, ]
train_neg <- schillingData_neg[-cv_ind, ]
#final CV
cv<-rbind(cv_pos,cv_neg)
#over sample the remaining pos class by replicating randomly
osize=length(train_neg$`data11$V2`)-length(train_pos$`data11$V2`)
oversamp_ind<-sample(seq_len(nrow(schillingData_pos)), size = osize,replace = T)
tr_pos_os<-train_pos[oversamp_ind,]
train_pos<-rbind(train_pos,tr_pos_os)
train_set<-rbind(train_pos,train_neg)
#####start training#######
y <- train_set$`data11$V2`
x <- train_set[c(2:length(train_set))]
x <- as.matrix(sapply(x, as.numeric))
n<-length(y)
#train SVM model
svp <- ksvm(x,y,type="C-svc",kernel="rbf",C=c,scaled=c())
# General summary
svp
xtest<-cv[c(2:length(train_set))]
ytest<-cv$`data11$V2`
ypred = predict(svp,xtest)
predList<-cbind(predList,ypred)
labList<-cbind(labList,ytest)
# Confusion table
cm<-table(ytest,ypred)
acc<-sum(diag(cm))/length(ytest)
#cat("Accuraccy:",acc*100,"%")
thisErr<-1-acc
#print(thisErr)
cvErrs<-c(cvErrs,thisErr)
}
errrbf<-c(errrbf, mean(cvErrs))
if(bestAcc<(1-mean(cvErrs))){
bestAcc<-1-mean(cvErrs)
bestMod<-svp
cat("best c:",c)
cat("ba",bestAcc)
}
}
pred.mat <- prediction(predList, labels = labList )
#plot CV ROCs
many.roc.perf = performance(pred.mat, measure = "tpr", x.measure = "fpr")
plot(many.roc.perf,main="ROC plot for cv sets",col=1,lwd=1)
abline(a=0, b= 1)
plot(clist,errrbf,type='l',ylim=c(0,0.2),xlab="C",ylab="Error rate",col=1,lwd=2,main='CrossValidaton error')
grid()
legend("topright",c('RBF'),lwd=2,col=c(1))
bestC<--2
bestC<-clist[which.min(errrbf)]
cat("Best C:",bestC,"from RBF using balanced schillingData, Err:", min(errrbf))
bestMod
##predict on test data
#read test set
X1625Data_encoded <- read_csv("1625Data_encoded.txt")
testy<-X1625Data_encoded$`data11$V2`
testx<-X1625Data_encoded[c(2:length(X1625Data_encoded))]
test_pred<- predict(bestMod,testx)
cm<-table(testy,test_pred)
acc<-sum(diag(cm))/length(testy)
cat("Accuraccy on 1625 data using schillingData model:",acc*100,"%")
pred <- prediction(test_pred,testy)
# Plot ROC curve
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
bestMod
##predict on test data
#read test set
X1625Data_encoded <- read_csv("1625Data_encoded.txt")
testy<-X1625Data_encoded$`data11$V2`
testx<-X1625Data_encoded[c(2:length(X1625Data_encoded))]
test_pred<- predict(bestMod,testx)
cm<-table(testy,test_pred)
acc<-sum(diag(cm))/length(testy)
cat("Accuraccy on 1625 data using schillingData model:",acc*100,"%")
pred <- prediction(test_pred,testy)
# Plot ROC curve
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf,title="TPR vs. FPR")
abline(a=0, b= 1)
auc<- performance(pred, measure = "auc")
cat("AUC ROC:",unlist(auc@y.values)[1])
# Plot precision/recall curve
perf <- performance(pred, measure = "prec", x.measure = "rec")
plot(perf,title="Precision-Recall")
